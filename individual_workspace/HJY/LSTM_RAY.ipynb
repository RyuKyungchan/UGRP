{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../tool_code/python_tool_code/function/')\n",
    "\n",
    "from DataPlot import Data_Load_Plot, Result_Plot, Loss_Plot\n",
    "from Scaling import time_scaling, time_inv_scaling\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4000)\n",
      "(1000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 load & plot\n",
    "fpath = \"../../data/synthetic_data/1000_data/\"\n",
    "\n",
    "Contaminated_data = np.load(fpath + \"contaminated_by_realistic\" + \".npy\")\n",
    "Clean_data = np.load(fpath + \"clean_data\" + \".npy\")\n",
    "Artifact_daata = Contaminated_data - Clean_data\n",
    "\n",
    "print(Contaminated_data.shape)\n",
    "print(Clean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1000, 4000)\n",
      "y: (1000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# Data Standard Scaling\n",
    "X, y, scaler_x, scaler_y = time_scaling(Contaminated_data, Clean_data, standard='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>\n",
      "-----------------------------\n",
      "X_train shape: (800, 4000)\n",
      "y_train shape: (800, 4000)\n",
      "-----------------------------\n",
      "X_test shape: (200, 4000)\n",
      "y_test shape: (200, 4000)\n",
      "-----------------------------\n",
      "<Unsqueezed>\n",
      "-----------------------------\n",
      "X_train shape: (800, 4000, 1)\n",
      "y_train shape: (800, 4000, 1)\n",
      "-----------------------------\n",
      "X_test shape: (200, 4000, 1)\n",
      "y_test shape: (200, 4000, 1)\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"<Original>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T, y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# 차원 추가 (LSTM은 세번째 차원 추가)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1) # Batch x length x 1\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1) # Batch x length x 1\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1], 1)\n",
    "\n",
    "print(\"<Unsqueezed>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T x 1 , y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Block(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM_Block, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size \n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size,\n",
    "                                num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) # 은닉 상태를 0으로 초기화\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) # 셀 상태를 0으로 초기화\n",
    "    \n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # LSTM 계층에 은닉 상태와 셀 상태 적용\n",
    "        # output = output.reshape(-1, self.hidden_size) # fc layer 적용을 위해 데이터를 1차원 형태로 조정\n",
    "        out = self.gelu(output)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class LSTM_time(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.net = nn.Sequential(*[\n",
    "            LSTM_Block(hidden_size, hidden_size, 1)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x): # B x T x 1\n",
    "        x = self.gelu(self.dropout(self.fc1(x))) # x: B x T x 128\n",
    "        x = self.net(x) # x: B x T x 128\n",
    "        x = self.fc2(x) # x: B x T x 1 -> B x T\n",
    "        x = self.gelu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_time(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gelu): GELU(approximate='none')\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (net): Sequential(\n",
      "    (0): LSTM_Block(\n",
      "      (lstm): LSTM(128, 128, batch_first=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (1): LSTM_Block(\n",
      "      (lstm): LSTM(128, 128, batch_first=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "input_size = 1  # 입력 크기\n",
    "hidden_size = 128 # 임의의 hidden layer 크기\n",
    "output_size = 1  # 출력 크기\n",
    "num_layers = 2  # 임의의 LSTM layer 개수\n",
    "\n",
    "model = LSTM_time(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "print(model)\n",
    "    \n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1659146726131439\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "Contaminated = torch.tensor([])\n",
    "Clean = torch.tensor([])\n",
    "SACed = torch.tensor([])\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        test_loss += loss.item() * x.size(0)\n",
    "\n",
    "        Contaminated = torch.cat((Contaminated, x.squeeze().cpu()), 0)\n",
    "        SACed = torch.cat((SACed, y_pred.squeeze().cpu()), 0)\n",
    "        Clean = torch.cat((Clean, y.squeeze().cpu()), 0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습함수 정의\n",
    "\n",
    "def train_lstm(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = LSTM_time(input_size = 1, \n",
    "                      hidden_size = config[\"hidden_size\"], \n",
    "                      output_size = 1, \n",
    "                      num_layers = config[\"num_layers\"]).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        if (epoch+1)%1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config[\"epochs\"]}] | Loss: {epoch_loss}')\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        Contaminated = torch.tensor([])\n",
    "        Clean = torch.tensor([])\n",
    "        SACed = torch.tensor([])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                test_loss += loss.item() * x.size(0)\n",
    "\n",
    "                Contaminated = torch.cat((Contaminated, x.squeeze().cpu()), 0)\n",
    "                SACed = torch.cat((SACed, y_pred.squeeze().cpu()), 0)\n",
    "                Clean = torch.cat((Clean, y.squeeze().cpu()), 0)\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "        train.report({\n",
    "            \"loss\": epoch_loss,\n",
    "            \"test_loss\": avg_test_loss\n",
    "        })\n",
    "\n",
    "    print(\"Training Complete\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 19:00:23,579\tINFO worker.py:1567 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-09-12 19:00:33,690\tINFO worker.py:1717 -- Failed to connect to the default Ray cluster address at 127.0.0.1:6379. This is most likely due to a previous Ray instance that has since crashed. To reset the default address to connect to, run `ray stop` or restart Ray with `ray start`.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py:1708\u001b[0m, in \u001b[0;36minit\u001b[1;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1708\u001b[0m     _global_node \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_at_exit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspawn_reaper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\node.py:259\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plasma_store_socket_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raylet_socket_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# Get the address info of the processes to connect to\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# from Redis or GCS.\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m     node_info \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_node_to_connect_for_driver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcs_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raylet_ip_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plasma_store_socket_name \u001b[38;5;241m=\u001b[39m node_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_store_socket_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\services.py:476\u001b[0m, in \u001b[0;36mget_node_to_connect_for_driver\u001b[1;34m(gcs_address, node_ip_address)\u001b[0m\n\u001b[0;32m    475\u001b[0m global_state\u001b[38;5;241m.\u001b[39m_initialize_global_state(gcs_options)\n\u001b[1;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mglobal_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_node_to_connect_for_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_ip_address\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\state.py:799\u001b[0m, in \u001b[0;36mGlobalState.get_node_to_connect_for_driver\u001b[1;34m(self, node_ip_address)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_connected()\n\u001b[1;32m--> 799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_state_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_node_to_connect_for_driver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_ip_address\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpython\\ray\\includes/global_state_accessor.pxi:253\u001b[0m, in \u001b[0;36mray._raylet.GlobalStateAccessor.get_node_to_connect_for_driver\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: b'GCS has started but no raylets have registered yet.'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m#test_best_model(best_result, smoke_test=smoke_test)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoke_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSMOKE_TEST\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(num_samples, max_num_epochs, gpus_per_trial, smoke_test)\u001b[0m\n\u001b[0;32m     17\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ASHAScheduler(\n\u001b[0;32m     18\u001b[0m     max_t\u001b[38;5;241m=\u001b[39mmax_num_epochs,\n\u001b[0;32m     19\u001b[0m     grace_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     20\u001b[0m     reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[0;32m     24\u001b[0m     tune\u001b[38;5;241m.\u001b[39mwith_resources(\n\u001b[0;32m     25\u001b[0m         tune\u001b[38;5;241m.\u001b[39mwith_parameters(train_lstm),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     param_space\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 36\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m best_result \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mget_best_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_result\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\tuner.py:379\u001b[0m, in \u001b[0;36mTuner.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes hyperparameter tuning job as configured and returns result.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03mFailure handling:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    RayTaskError: If user-provided trainable raises an exception\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_ray_client:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     (\n\u001b[0;32m    382\u001b[0m         progress_reporter,\n\u001b[0;32m    383\u001b[0m         string_queue,\n\u001b[0;32m    384\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_remote_tuner_for_jupyter_progress_reporting()\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\impl\\tuner_internal.py:477\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    475\u001b[0m param_space \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_restored:\n\u001b[1;32m--> 477\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resume(trainable, param_space)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\impl\\tuner_internal.py:596\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[1;34m(self, trainable, param_space)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001b[39;00m\n\u001b[0;32m    584\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[0;32m    595\u001b[0m }\n\u001b[1;32m--> 596\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_remote_string_queue()\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\tune.py:538\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     error_message_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentrypoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtune.run(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_space_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestore_entrypoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtune.run(..., resume=True)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    536\u001b[0m     }\n\u001b[1;32m--> 538\u001b[0m \u001b[43m_ray_auto_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_message_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentrypoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _remote \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     _remote \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mray\u001b[38;5;241m.\u001b[39mis_connected()\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\tune.py:262\u001b[0m, in \u001b[0;36m_ray_auto_init\u001b[1;34m(entrypoint)\u001b[0m\n\u001b[0;32m    260\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTUNE_DISABLE_AUTO_INIT=1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m detected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mis_initialized():\n\u001b[1;32m--> 262\u001b[0m     \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing Ray automatically. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor cluster usage or custom Ray initialization, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall `ray.init(...)` before `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentrypoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py:1724\u001b[0m, in \u001b[0;36minit\u001b[1;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[0;32m   1716\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gcs_address \u001b[38;5;241m==\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mread_ray_address(_temp_dir):\n\u001b[0;32m   1717\u001b[0m             logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1718\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to connect to the default Ray cluster address at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1719\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgcs_address\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is most likely due to a previous Ray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`ray start`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m             )\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;66;03m# Log a message to find the Ray address that we connected to and the\u001b[39;00m\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;66;03m# dashboard URL.\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ray_constants\u001b[38;5;241m.\u001b[39mRAY_OVERRIDE_DASHBOARD_URL \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "\u001b[1;31mConnectionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# Set this to True for a smoke test that runs with a small synthetic dataset.\n",
    "SMOKE_TEST = False\n",
    "\n",
    "def main(num_samples, max_num_epochs, gpus_per_trial=2, smoke_test=False):\n",
    "    config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"epochs\": max_num_epochs,\n",
    "    \"num_layers\": tune.sample_from(lambda _: np.random.randint(1, 20)),\n",
    "    \"hidden_size\" : tune.sample_from(lambda _: np.random.randint(100, 200))\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_lstm),\n",
    "            resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"loss\", \"min\", \"last\")\n",
    "\n",
    "    print(f\"Best trial config: {best_result.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_result.metrics['loss']}\")\n",
    "\n",
    "main(num_samples=1, max_num_epochs=500, gpus_per_trial=0, smoke_test=SMOKE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
