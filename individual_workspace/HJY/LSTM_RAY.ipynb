{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\__init__.py:1827\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[38;5;66;03m# nn.quant* depends on ao -- so should be after those.\u001b[39;00m\n\u001b[0;32m   1826\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizable\u001b[39;00m\n\u001b[1;32m-> 1827\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantized\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqat\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintrinsic\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\quantized\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m modules  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantized\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\ao\\nn\\quantized\\dynamic\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\ao\\nn\\quantized\\dynamic\\modules\\__init__.py:2\u001b[0m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, GRU, LSTMCell, RNNCell, GRUCell\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, ConvTranspose1d, ConvTranspose2d, ConvTranspose3d\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:839\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:934\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../tool_code/python_tool_code/function/')\n",
    "\n",
    "from DataPlot import Data_Load_Plot, Result_Plot, Loss_Plot\n",
    "from Scaling import time_scaling, time_inv_scaling\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4000)\n",
      "(1000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 load & plot\n",
    "fpath = \"../../data/synthetic_data/1000_data/\"\n",
    "\n",
    "Contaminated_data = np.load(fpath + \"contaminated_by_realistic\" + \".npy\")\n",
    "Clean_data = np.load(fpath + \"clean_data\" + \".npy\")\n",
    "Artifact_daata = Contaminated_data - Clean_data\n",
    "\n",
    "print(Contaminated_data.shape)\n",
    "print(Clean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1000, 4000)\n",
      "y: (1000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# Data Standard Scaling\n",
    "X, y, scaler_x, scaler_y = time_scaling(Contaminated_data, Clean_data, standard='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>\n",
      "-----------------------------\n",
      "X_train shape: (800, 4000)\n",
      "y_train shape: (800, 4000)\n",
      "-----------------------------\n",
      "X_test shape: (200, 4000)\n",
      "y_test shape: (200, 4000)\n",
      "-----------------------------\n",
      "<Unsqueezed>\n",
      "-----------------------------\n",
      "X_train shape: (800, 4000, 1)\n",
      "y_train shape: (800, 4000, 1)\n",
      "-----------------------------\n",
      "X_test shape: (200, 4000, 1)\n",
      "y_test shape: (200, 4000, 1)\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"<Original>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T, y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# 차원 추가 (LSTM은 세번째 차원 추가)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1) # Batch x length x 1\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1) # Batch x length x 1\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1], 1)\n",
    "\n",
    "print(\"<Unsqueezed>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T x 1 , y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Block(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM_Block, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size \n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size,\n",
    "                                num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) # 은닉 상태를 0으로 초기화\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) # 셀 상태를 0으로 초기화\n",
    "    \n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # LSTM 계층에 은닉 상태와 셀 상태 적용\n",
    "        # output = output.reshape(-1, self.hidden_size) # fc layer 적용을 위해 데이터를 1차원 형태로 조정\n",
    "        out = self.gelu(output)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class LSTM_time(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.net = nn.Sequential(*[\n",
    "            LSTM_Block(hidden_size, hidden_size, 1)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x): # B x T x 1\n",
    "        x = self.gelu(self.dropout(self.fc1(x))) # x: B x T x 128\n",
    "        x = self.net(x) # x: B x T x 128\n",
    "        x = self.fc2(x) # x: B x T x 1 -> B x T\n",
    "        x = self.gelu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_time(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gelu): GELU(approximate='none')\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (net): Sequential(\n",
      "    (0): LSTM_Block(\n",
      "      (lstm): LSTM(128, 128, batch_first=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (1): LSTM_Block(\n",
      "      (lstm): LSTM(128, 128, batch_first=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "input_size = 1  # 입력 크기\n",
    "hidden_size = 128 # 임의의 hidden layer 크기\n",
    "output_size = 1  # 출력 크기\n",
    "num_layers = 2  # 임의의 LSTM layer 개수\n",
    "\n",
    "model = LSTM_time(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "print(model)\n",
    "    \n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.15748783826828003\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "Contaminated = torch.tensor([])\n",
    "Clean = torch.tensor([])\n",
    "SACed = torch.tensor([])\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        test_loss += loss.item() * x.size(0)\n",
    "\n",
    "        Contaminated = torch.cat((Contaminated, x.squeeze().cpu()), 0)\n",
    "        SACed = torch.cat((SACed, y_pred.squeeze().cpu()), 0)\n",
    "        Clean = torch.cat((Clean, y.squeeze().cpu()), 0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#학습함수 정의\n",
    "\n",
    "def train_lstm(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = LSTM_time(input_size = 1, \n",
    "                      hidden_size = config[\"hidden_size\"], \n",
    "                      output_size = 1, \n",
    "                      num_layers = config[\"num_layers\"]).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        if (epoch+1)%1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config[\"epochs\"]}] | Loss: {epoch_loss}')\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        Contaminated = torch.tensor([])\n",
    "        Clean = torch.tensor([])\n",
    "        SACed = torch.tensor([])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                test_loss += loss.item() * x.size(0)\n",
    "\n",
    "                Contaminated = torch.cat((Contaminated, x.squeeze().cpu()), 0)\n",
    "                SACed = torch.cat((SACed, y_pred.squeeze().cpu()), 0)\n",
    "                Clean = torch.cat((Clean, y.squeeze().cpu()), 0)\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "        train.report({\n",
    "            \"loss\": epoch_loss,\n",
    "            \"test_loss\": avg_test_loss\n",
    "        })\n",
    "\n",
    "    print(\"Training Complete\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-09-12 19:37:25</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:20.24        </td></tr>\n",
       "<tr><td>Memory:      </td><td>23.8/23.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 12.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_lstm_88afb_00000</td><td style=\"text-align: right;\">           1</td><td>C:/Users/stell/AppData/Local/Temp/ray/session_2024-09-12_19-33-47_053849_22256/artifacts/2024-09-12_19-34-04/train_lstm_2024-09-12_19-34-00/driver_artifacts/train_lstm_88afb_00000_0_lr=0.0034_2024-09-12_19-34-08/error.txt</td></tr>\n",
       "<tr><td>train_lstm_88afb_00001</td><td style=\"text-align: right;\">           1</td><td>C:/Users/stell/AppData/Local/Temp/ray/session_2024-09-12_19-33-47_053849_22256/artifacts/2024-09-12_19-34-04/train_lstm_2024-09-12_19-34-00/driver_artifacts/train_lstm_88afb_00001_1_lr=0.0003_2024-09-12_19-34-08/error.txt</td></tr>\n",
       "<tr><td>train_lstm_88afb_00002</td><td style=\"text-align: right;\">           1</td><td>C:/Users/stell/AppData/Local/Temp/ray/session_2024-09-12_19-33-47_053849_22256/artifacts/2024-09-12_19-34-04/train_lstm_2024-09-12_19-34-00/driver_artifacts/train_lstm_88afb_00002_2_lr=0.0039_2024-09-12_19-34-08/error.txt</td></tr>\n",
       "<tr><td>train_lstm_88afb_00006</td><td style=\"text-align: right;\">           1</td><td>C:/Users/stell/AppData/Local/Temp/ray/session_2024-09-12_19-33-47_053849_22256/artifacts/2024-09-12_19-34-04/train_lstm_2024-09-12_19-34-00/driver_artifacts/train_lstm_88afb_00006_6_lr=0.0002_2024-09-12_19-34-09/error.txt</td></tr>\n",
       "<tr><td>train_lstm_88afb_00009</td><td style=\"text-align: right;\">           1</td><td>C:/Users/stell/AppData/Local/Temp/ray/session_2024-09-12_19-33-47_053849_22256/artifacts/2024-09-12_19-34-04/train_lstm_2024-09-12_19-34-00/driver_artifacts/train_lstm_88afb_00009_9_lr=0.0001_2024-09-12_19-34-10/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_lstm_88afb_00003</td><td>RUNNING </td><td>127.0.0.1:22584</td><td style=\"text-align: right;\">0.000127639</td></tr>\n",
       "<tr><td>train_lstm_88afb_00004</td><td>RUNNING </td><td>127.0.0.1:10232</td><td style=\"text-align: right;\">0.000163006</td></tr>\n",
       "<tr><td>train_lstm_88afb_00005</td><td>RUNNING </td><td>127.0.0.1:15804</td><td style=\"text-align: right;\">0.00120717 </td></tr>\n",
       "<tr><td>train_lstm_88afb_00007</td><td>RUNNING </td><td>127.0.0.1:21588</td><td style=\"text-align: right;\">0.00146191 </td></tr>\n",
       "<tr><td>train_lstm_88afb_00008</td><td>RUNNING </td><td>127.0.0.1:24520</td><td style=\"text-align: right;\">0.00566781 </td></tr>\n",
       "<tr><td>train_lstm_88afb_00010</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.0057547  </td></tr>\n",
       "<tr><td>train_lstm_88afb_00011</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00508523 </td></tr>\n",
       "<tr><td>train_lstm_88afb_00000</td><td>ERROR   </td><td>127.0.0.1:23440</td><td style=\"text-align: right;\">0.00342057 </td></tr>\n",
       "<tr><td>train_lstm_88afb_00001</td><td>ERROR   </td><td>127.0.0.1:20216</td><td style=\"text-align: right;\">0.000320307</td></tr>\n",
       "<tr><td>train_lstm_88afb_00002</td><td>ERROR   </td><td>127.0.0.1:27048</td><td style=\"text-align: right;\">0.00391166 </td></tr>\n",
       "<tr><td>train_lstm_88afb_00006</td><td>ERROR   </td><td>127.0.0.1:21512</td><td style=\"text-align: right;\">0.000164732</td></tr>\n",
       "<tr><td>train_lstm_88afb_00009</td><td>ERROR   </td><td>127.0.0.1:19732</td><td style=\"text-align: right;\">0.000135759</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (61 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=20216)\u001b[0m C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(pid=20216)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(pid=22584)\u001b[0m C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=22584)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "2024-09-12 19:35:28,128\tERROR tune_controller.py:1332 -- Trial task failed for trial train_lstm_88afb_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27048, ip=127.0.0.1, actor_id=0472c727fd2cc5b3c46776ac01000000, repr=train_lstm)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 724, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 334, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 53, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\1542505607.py\", line 20, in train_lstm\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 41, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 17, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 917, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.70 GiB. GPU 0 has a total capacity of 12.00 GiB of which 8.50 GiB is free. Of the allocated memory 827.44 MiB is allocated by PyTorch, and 1.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2024-09-12 19:35:39,678\tERROR tune_controller.py:1332 -- Trial task failed for trial train_lstm_88afb_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23440, ip=127.0.0.1, actor_id=4e3f8208ff92714ec1c0afa901000000, repr=train_lstm)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 724, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 334, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 53, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\1542505607.py\", line 20, in train_lstm\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 41, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 17, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 917, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 903.72 MiB is allocated by PyTorch, and 1.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[36m(pid=21512)\u001b[0m C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=21512)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-09-12 19:36:30,117\tERROR tune_controller.py:1332 -- Trial task failed for trial train_lstm_88afb_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=20216, ip=127.0.0.1, actor_id=643adc59362fb3453fb6c0f601000000, repr=train_lstm)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 724, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 334, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 53, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\1542505607.py\", line 20, in train_lstm\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 41, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 17, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 917, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 3.89 GiB is allocated by PyTorch, and 32.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2024-09-12 19:36:31,955\tERROR tune_controller.py:1332 -- Trial task failed for trial train_lstm_88afb_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=21512, ip=127.0.0.1, actor_id=bba2bda550ad9124268b6e8201000000, repr=train_lstm)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 724, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 334, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 53, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\1542505607.py\", line 20, in train_lstm\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 41, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 17, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 917, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 423.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[36m(pid=24520)\u001b[0m C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=24520)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-09-12 19:36:57,084\tERROR tune_controller.py:1332 -- Trial task failed for trial train_lstm_88afb_00009\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=19732, ip=127.0.0.1, actor_id=f95089223bf784e7ce8dd8cf01000000, repr=train_lstm)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 724, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 334, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 53, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\1542505607.py\", line 20, in train_lstm\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 41, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 17, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 917, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 464.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 2.40 GiB is allocated by PyTorch, and 11.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2024-09-12 19:37:38,796\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=24520, ip=127.0.0.1, actor_id=616b3a709b68ba0cf05eccc901000000, repr=train_lstm)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 724, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 334, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 53, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\1542505607.py\", line 20, in train_lstm\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 41, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\AppData\\Local\\Temp\\ipykernel_26300\\3943842365.py\", line 17, in forward\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\stell\\anaconda3\\envs\\UGRP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 917, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 0 has a total capacity of 12.00 GiB of which 9.04 GiB is free. Of the allocated memory 648.10 MiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# Set this to True for a smoke test that runs with a small synthetic dataset.\n",
    "SMOKE_TEST = False\n",
    "\n",
    "def main(num_samples, max_num_epochs, gpus_per_trial=2, smoke_test=False):\n",
    "    config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"epochs\": max_num_epochs,\n",
    "    \"num_layers\": tune.sample_from(lambda _: np.random.randint(1, 10)),\n",
    "    \"hidden_size\" : tune.sample_from(lambda _: np.random.randint(100, 200))\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_lstm),\n",
    "            resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"loss\", \"min\", \"last\")\n",
    "\n",
    "    print(f\"Best trial config: {best_result.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_result.metrics['loss']}\")\n",
    "\n",
    "main(num_samples=12, max_num_epochs=5, gpus_per_trial=0, smoke_test=SMOKE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
