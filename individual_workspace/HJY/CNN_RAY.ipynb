{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../tool_code/function/') # \"~~/tool_code/plot/\" (상대 경로)\n",
    "\n",
    "from DataPlot import Data_Load_Plot, Result_Plot, Train_Loss_Plot\n",
    "from Scaling import time_scaling, time_inv_scaling\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1000, 4000)\n",
      "y: (1000, 4000)\n",
      "(1000, 4000)\n",
      "(1000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 load & plot\n",
    "fpath = \"../../data/synthetic_data/\"\n",
    "\n",
    "Contaminated_data = np.load(fpath + \"contaminated_by_realistic\" + \".npy\")\n",
    "Clean_data = np.load(fpath + \"clean_data\" + \".npy\")\n",
    "Artifact_daata = Contaminated_data - Clean_data\n",
    "\n",
    "# Data Standard Scaling\n",
    "X, y, scaler_x, scaler_y = time_scaling(Contaminated_data, Clean_data, standard='x')\n",
    "\n",
    "print(Contaminated_data.shape)\n",
    "print(Clean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>\n",
      "-----------------------------\n",
      "X_train shape: (800, 4000)\n",
      "y_train shape: (800, 4000)\n",
      "-----------------------------\n",
      "X_test shape: (200, 4000)\n",
      "y_test shape: (200, 4000)\n",
      "-----------------------------\n",
      "<Unsqueezed>\n",
      "-----------------------------\n",
      "X_train shape: (800, 1, 4000)\n",
      "y_train shape: (800, 1, 4000)\n",
      "-----------------------------\n",
      "X_test shape: (200, 1, 4000)\n",
      "y_test shape: (200, 1, 4000)\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"<Original>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T, y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# 차원 추가 (LSTM은 세번째 차원 추가)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1]) # Batch x length x 1\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "y_train = y_train.reshape(y_train.shape[0], 1, y_train.shape[1]) # Batch x length x 1\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, y_test.shape[1])\n",
    "\n",
    "print(\"<Unsqueezed>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T x 1 , y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "#train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "#test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (6): GELU(approximate='none')\n",
      "    (7): Conv1d(16, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      "  (drop): Dropout1d(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, hidden_dim=16, kernel_size=3, dropout_rate=0.25):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, hidden_dim, kernel_size, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim * 2, kernel_size, padding=1),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(hidden_dim * 2, hidden_dim, kernel_size, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(hidden_dim, out_channels, kernel_size, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.drop = nn.Dropout1d(dropout_rate)\n",
    "\n",
    "    def forward(self, x):  # x: B x 1 x T\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "def train_cnn(config, checkpoint_dir=None):\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=[\"batch_size\"], shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    model = CNN(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        kernel_size=config[\"kernel_size\"],\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "        tune.report(loss=running_loss / len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 06:32:48,745\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "2024-08-16 06:32:52,040\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 06:34:06,706\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\stell\\AppData\\Local\\Temp\\ray\\session_2024-08-16_06-32-46_981402_16356\\artifacts\\2024-08-16_06-32-52\\train_cnn_2024-08-16_06-32-52\\driver_artifacts\\train_cnn_ed3b1_00000_0_batch_size=16,dropout_rate=0.3678,hidden_dim=16,kernel_size=7,lr=0.0087_2024-08-16_06-34-06\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:\\\\Users\\\\stell\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2024-08-16_06-32-46_981402_16356\\\\artifacts\\\\2024-08-16_06-32-52\\\\train_cnn_2024-08-16_06-32-52\\\\driver_artifacts\\\\train_cnn_ed3b1_00000_0_batch_size=16,dropout_rate=0.3678,hidden_dim=16,kernel_size=7,lr=0.0087_2024-08-16_06-34-06'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:\\\\Users\\\\stell\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2024-08-16_06-32-46_981402_16356\\\\artifacts\\\\2024-08-16_06-32-52\\\\train_cnn_2024-08-16_06-32-52\\\\driver_artifacts\\\\train_cnn_ed3b1_00000_0_batch_size=16,dropout_rate=0.3678,hidden_dim=16,kernel_size=7,lr=0.0087_2024-08-16_06-34-06'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 25\u001b[0m\n\u001b[0;32m      9\u001b[0m search_space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m]),\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m])\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ASHAScheduler(\n\u001b[0;32m     18\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_cnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 실험할 샘플 수\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/ray_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 짧은 경로 설정\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest config: \u001b[39m\u001b[38;5;124m\"\u001b[39m, analysis\u001b[38;5;241m.\u001b[39mbest_config)\n\u001b[0;32m     37\u001b[0m best_config \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_best_config(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\site-packages\\ray\\tune\\tune.py:994\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 994\u001b[0m         \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n\u001b[0;32m    996\u001b[0m             _report_progress(runner, progress_reporter)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:682\u001b[0m, in \u001b[0;36mTuneController.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_update_trial_queue()\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# Start actors for added trials\u001b[39;00m\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_add_actors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnext(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:860\u001b[0m, in \u001b[0;36mTuneController._maybe_add_actors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_cache\u001b[38;5;241m.\u001b[39mincrease_max(trial_to_run\u001b[38;5;241m.\u001b[39mplacement_group_factory)\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# schedule_trial_actor also potentially uses cached actors\u001b[39;00m\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_trial_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_to_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;66;03m# Otherwise, only try to use the cached actor\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _dedup_logs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial_to_run_reuse\u001b[39m\u001b[38;5;124m\"\u001b[39m, trial_to_run\u001b[38;5;241m.\u001b[39mtrial_id):\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:974\u001b[0m, in \u001b[0;36mTuneController._schedule_trial_actor\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    970\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to schedule new ACTOR for trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Trial\u001b[38;5;241m.\u001b[39mPENDING\n\u001b[1;32m--> 974\u001b[0m \u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_local_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# We checkpoint metadata here to try mitigating logdir duplication\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_trial_to_checkpoint(trial)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\site-packages\\ray\\tune\\experiment\\trial.py:653\u001b[0m, in \u001b[0;36mTrial.init_local_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(logdir_path)) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_path_length:\n\u001b[0;32m    647\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path to the trial log directory is too long \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(max length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_path_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `trial_dirname_creator` to shorten the path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogdir_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    652\u001b[0m     )\n\u001b[1;32m--> 653\u001b[0m \u001b[43mlogdir_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvalidate_json_state()\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\pathlib.py:1328\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_dir():\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\torch1\\lib\\pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:\\\\Users\\\\stell\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2024-08-16_06-32-46_981402_16356\\\\artifacts\\\\2024-08-16_06-32-52\\\\train_cnn_2024-08-16_06-32-52\\\\driver_artifacts\\\\train_cnn_ed3b1_00000_0_batch_size=16,dropout_rate=0.3678,hidden_dim=16,kernel_size=7,lr=0.0087_2024-08-16_06-34-06'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "search_space = {\n",
    "    \"hidden_dim\": tune.choice([16, 32, 64]),\n",
    "    \"kernel_size\": tune.choice([3, 5, 7]),\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.5),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"batch_size\": tune.choice([16, 32, 64])\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_cnn,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=1000,  # 실험할 샘플 수\n",
    "    scheduler=scheduler,\n",
    "    storage_path=\"C:/ray_results\",  # 짧은 경로 설정\n",
    "    log_to_file=True\n",
    ")\n",
    "\n",
    "print(\"Best config: \", analysis.best_config)\n",
    "\n",
    "best_config = analysis.get_best_config(metric=\"loss\", mode=\"min\")\n",
    "print(f\"Best config: {best_config}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
