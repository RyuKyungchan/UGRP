{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time+PSD를 input으로 넣고 Time+PSD를 Loss로 설정\n",
    "이때 PSD는 welch's method로 얻음\n",
    "#### X에 맞춰서 y를 scaling (X, y 각각 scaling 했을 때 학습이 잘 안됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../tool_code/python_tool_code/function/') # \"~~/tool_code/plot/\" (상대 경로)\n",
    "sys.path.append('../../../tool_code/python_tool_code/frequency_dataset_generation/')\n",
    "\n",
    "from DataPlot import Data_Load_Plot, Result_Plot, Loss_Plot\n",
    "from Scaling import time_scaling, time_inv_scaling\n",
    "from FFT_func import FFT\n",
    "from Welch_func import Welch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 load & plot\n",
    "# datapath='../../../data/synthetic_data/'\n",
    "datapath = 'C:/Users/User/Desktop/SCH/paper_data/'\n",
    "\n",
    "Contaminated_data, Clean_data, Artifact_data = Data_Load_Plot(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Standard Scaling\n",
    "X_time, y_time, scaler_x, scaler_y = time_scaling(Contaminated_data, Clean_data, standard='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSD\n",
    "freqs, _, _, X_psd = FFT(X_time, fs=2000, single_sided=False)\n",
    "_, _, _, y_psd = FFT(y_time, fs=2000, single_sided=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - time series Data preprocessing\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_time, y_time, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"<Original>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X1_train shape: {X1_train.shape}\\ny1_train shape: {y1_train.shape}\") # x : B x T, y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X1_test shape: {X1_test.shape}\\ny1_test shape: {y1_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "train_dataset1 = TensorDataset(torch.tensor(X1_train, dtype=torch.float32), torch.tensor(y1_train, dtype=torch.float32))\n",
    "test_dataset1 = TensorDataset(torch.tensor(X1_test, dtype=torch.float32), torch.tensor(y1_test, dtype=torch.float32))\n",
    "\n",
    "train_loader1 = DataLoader(dataset=train_dataset1, batch_size=32, shuffle=True)\n",
    "test_loader1 = DataLoader(dataset=test_dataset1, batch_size=32, shuffle=False)\n",
    "\n",
    "# 2 - psd Data preprocessing\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_psd, y_psd, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"<Original>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X2_train shape: {X2_train.shape}\\ny2_train shape: {y2_train.shape}\") # x : B x T, y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X2_test shape: {X2_test.shape}\\ny2_test shape: {y2_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "train_dataset2 = TensorDataset(torch.tensor(X2_train, dtype=torch.float32), torch.tensor(y2_train, dtype=torch.float32))\n",
    "test_dataset2 = TensorDataset(torch.tensor(X2_test, dtype=torch.float32), torch.tensor(y2_test, dtype=torch.float32))\n",
    "\n",
    "train_loader2 = DataLoader(dataset=train_dataset2, batch_size=32, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_dataset2, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        in_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_size, hidden_size))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "            in_size = hidden_size\n",
    "        layers.append(nn.Linear(in_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class JointSpaceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointSpaceModel, self).__init__()\n",
    "        self.mlp_time = MLP(input_size=4000, hidden_sizes=[512, 256, 128], output_size=64)\n",
    "        self.mlp_psd = MLP(input_size=4000, hidden_sizes=[512, 256, 128], output_size=64)\n",
    "        self.fc_joint = nn.Linear(128, 32)\n",
    "        self.fc_recover = nn.Linear(32, 4000)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, time_series, psd): # time_series : B x 4000, psd : B x 4000\n",
    "        time_features = self.mlp_time(time_series) # B x 4000 -> B x 64\n",
    "        psd_features = self.mlp_psd(psd) # B x 4000 -> B x 64\n",
    "        joint_features = torch.cat((time_features, psd_features), dim=1) # B x 128\n",
    "        joint_space = self.gelu(self.fc_joint(joint_features)) # B x 128 -> B x 32\n",
    "        recovered_time_series = self.gelu(self.fc_recover(joint_space)) # B x 32 -> B x 4000        \n",
    "        return recovered_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JointSpaceModel().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "num_epochs = 500\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# Learning rate scheduler 초기화\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for (x1, y1), (x2, y2) in zip(train_loader1, train_loader2):\n",
    "        x1, y1 = x1.to(device), y1.to(device)\n",
    "        x2, y2 = x2.to(device), y2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 예측\n",
    "        y_pred = model(x1, x2)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = criterion(y_pred, y1)\n",
    "        \n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * x1.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader1.dataset)\n",
    "    loss_list.append(epoch_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loss Plot\n",
    "Loss_Plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "Contaminated = torch.tensor([])\n",
    "Clean = torch.tensor([])\n",
    "SACed = torch.tensor([])\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for (x1, y1), (x2, y2) in zip(test_loader1, test_loader2):\n",
    "        x1, y1 = x1.to(device), y1.to(device)\n",
    "        x2, y2 = x2.to(device), y2.to(device)\n",
    "        \n",
    "        # 모델 예측\n",
    "        y_pred = model(x1, x2)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = criterion(y_pred, y1)\n",
    "        \n",
    "        test_loss += loss.item() * x1.size(0)\n",
    "\n",
    "        Contaminated = torch.cat((Contaminated, x1.cpu().detach()), dim=0)\n",
    "        Clean = torch.cat((Clean, y1.cpu().detach()), dim=0)\n",
    "        SACed = torch.cat((SACed, y_pred.cpu().detach()), dim=0)\n",
    "\n",
    "test_loss /= len(test_loader1.dataset)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Contaminated.shape)\n",
    "\n",
    "# Inverse Scaling\n",
    "Contaminated_inv_scaled, SACed_inv_scaled, Clean_inv_scaled = time_inv_scaling(Contaminated, SACed, Clean, scaler_x)\n",
    "\n",
    "save_path = '../../../result/data_10000/MLP/'\n",
    "save_title = 'MLP_IO_time+psd'\n",
    "# 결과 Plot\n",
    "Result_Plot(Contaminated_inv_scaled, SACed_inv_scaled, Clean_inv_scaled, save_path, save_title) # inverse scaled data를 input으로 넣음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
