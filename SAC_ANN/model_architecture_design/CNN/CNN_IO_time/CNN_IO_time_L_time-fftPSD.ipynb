{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Signal을 input으로 넣고 Time+PSD를 Loss로 설정\n",
    "#### X에 맞춰서 y를 scaling (X, y 각각 scaling 했을 때 학습이 잘 안됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import windows\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../../tool_code/python_tool_code/function/') # \"~~/tool_code/plot/\" (상대 경로)\n",
    "\n",
    "from DataPlot import Data_Load_Plot, Result_Plot, Loss_Plot\n",
    "from Scaling import time_scaling, time_inv_scaling\n",
    "\n",
    "sys.path.append('../../../../tool_code/python_tool_code/frequency_dataset_generation/')\n",
    "from FFT_func import FFT\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 load & plot\n",
    "datapath='C:/Users/stell/OneDrive/바탕 화면/paper_data/' \n",
    "\n",
    "Contaminated_data, Clean_data, Artifact_data = Data_Load_Plot(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Standard Scaling\n",
    "X, y, scaler_x, scaler_y = time_scaling(Contaminated_data, Clean_data, standard='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"<Original>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T, y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# 차원 추가 (LSTM은 세번째 차원 추가)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1]) # Batch x length x 1\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "y_train = y_train.reshape(y_train.shape[0], 1, y_train.shape[1]) # Batch x length x 1\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, y_test.shape[1])\n",
    "\n",
    "print(\"<Unsqueezed>\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\") # x : B x T x 1 , y : B x T\n",
    "print(\"-----------------------------\")\n",
    "print(f\"X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(32, 16, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(16, 1, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.drop = nn.Dropout1d(0.25)\n",
    "\n",
    "    def forward(self, x): # x : B x 1 x T\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# 가중치 초기화 함수 정의\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)  # Xavier 초기화\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)  # 편향 초기화\n",
    "\n",
    "# 모델의 가중치 초기화 적용\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의 \n",
    "\n",
    "class LossFunction(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(LossFunction, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "        # 학습 가능한 가중치 파라미터\n",
    "        self.signal_weight = nn.Parameter(torch.tensor(0.1, requires_grad=True))\n",
    "        self.fft_weight = nn.Parameter(torch.tensor(0.1, requires_grad=True))\n",
    "\n",
    "    def forward(self, y_pred, y, y_pred_fft, y_fft):\n",
    "        signal_loss = self.mse_loss(y_pred, y)\n",
    "        fft_loss = self.mse_loss(y_pred_fft, y_fft)\n",
    "\n",
    "        # 가중치 적용\n",
    "        total_loss = self.alpha * (signal_loss * self.signal_weight) + \\\n",
    "                     (1 - self.alpha) * (fft_loss * self.fft_weight)\n",
    "\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = LossFunction(alpha=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "num_epochs = 500\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:   \n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(x) # y_pred : B x T x 1\n",
    "        \n",
    "        # 각 배치 항목에 대해 FFT를 수행하고 스펙트럼 계산\n",
    "        batch_size, seq_len, _ = y.shape\n",
    "        y = y.view(batch_size, seq_len, -1)\n",
    "        y_pred = y_pred.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # Ensure y is a PyTorch tensor and detach it before converting to NumPy\n",
    "        y_cpu = y.detach().cpu().numpy() if isinstance(y, torch.Tensor) else y\n",
    "        y_pred_cpu = y_pred.detach().cpu().numpy()\n",
    "\n",
    "        _, _, _, y_fft = FFT(y_cpu, fs=2000, single_sided=True)\n",
    "        _, _, _, y_pred_fft = FFT(y_pred_cpu, fs=2000, single_sided=True)\n",
    "\n",
    "        y_pred_fft = torch.tensor(y_pred_fft, dtype=torch.float32).to(y_pred.device)\n",
    "        y_fft = torch.tensor(y_fft, dtype=torch.float32).to(y.device)\n",
    "\n",
    "        \n",
    "        # 배치 크기 불일치 처리\n",
    "        if y_pred_fft.shape[0] != y_fft.shape[0]:\n",
    "            min_batch_size = min(y_pred_fft.shape[0], y_fft.shape[0])\n",
    "            y_pred_fft = y_pred_fft[:min_batch_size]\n",
    "            y_fft = y_fft[:min_batch_size]\n",
    "\n",
    "        if y_pred.shape[0] != y.shape[0]:\n",
    "            min_batch_size = min(y_pred.shape[0], y.shape[0])\n",
    "            y_pred = y_pred[:min_batch_size]\n",
    "            y = y[:min_batch_size]\n",
    "\n",
    "        loss = criterion(y_pred, y, y_pred_fft, y_fft)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "    if (epoch+1)%5 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loss Plot\n",
    "Loss_Plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "Contaminated = torch.tensor([])\n",
    "Clean = torch.tensor([])\n",
    "SACed = torch.tensor([])\n",
    "SACed_spectro = torch.tensor([])\n",
    "Clean_spectro = torch.tensor([])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[0] # x : B x T x 1\n",
    "        y = batch[1] # y : B x T\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(x) # y_pred : B x T\n",
    "\n",
    "        # 각 배치 항목에 대해 FFT를 수행하고 스펙트럼 계산\n",
    "        batch_size, seq_len, _ = y.shape\n",
    "        y = y.view(batch_size, seq_len, -1)\n",
    "        y_pred = y_pred.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # Ensure y is a PyTorch tensor and detach it before converting to NumPy\n",
    "        y_cpu = y.detach().cpu().numpy() if isinstance(y, torch.Tensor) else y\n",
    "        y_pred_cpu = y_pred.detach().cpu().numpy()\n",
    "\n",
    "        _, _, _, y_fft = FFT(y_cpu, fs=2000, single_sided=True)\n",
    "        _, _, _, y_pred_fft = FFT(y_pred_cpu, fs=2000, single_sided=True)\n",
    "        \n",
    "        y_pred_fft = torch.tensor(y_pred_fft, dtype=torch.float32).to(y_pred.device)\n",
    "        y_fft = torch.tensor(y_fft, dtype=torch.float32).to(y.device)\n",
    "\n",
    "        # 배치 크기 불일치 처리\n",
    "        if y_pred_fft.shape[0] != y_fft.shape[0]:\n",
    "            min_batch_size = min(y_pred_fft.shape[0], y_fft.shape[0])\n",
    "            y_pred_fft = y_pred_fft[:min_batch_size]\n",
    "            y_fft = y_fft[:min_batch_size]\n",
    "\n",
    "        if y_pred.shape[0] != y.shape[0]:\n",
    "            min_batch_size = min(y_pred.shape[0], y.shape[0])\n",
    "            y_pred = y_pred[:min_batch_size]\n",
    "            y = y[:min_batch_size]\n",
    "\n",
    "        loss = criterion(y_pred, y, y_pred_fft, y_fft)\n",
    "        \n",
    "        Contaminated = torch.cat((Contaminated, x.squeeze().cpu()), 0)\n",
    "        SACed = torch.cat((SACed, y_pred.squeeze().cpu()), 0)\n",
    "        Clean = torch.cat((Clean, y.squeeze().cpu()), 0)\n",
    "        SACed_spectro = torch.cat((SACed_spectro, y_pred_fft.cpu()), 0)\n",
    "        Clean_spectro = torch.cat((Clean_spectro, y_fft.cpu()), 0)\n",
    "\n",
    "val_loss = criterion(SACed, Clean, SACed_spectro, Clean_spectro)\n",
    "print(f'Validation Loss: {val_loss.item()}')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Scaling\n",
    "Contaminated_inv_scaled, SACed_inv_scaled, Clean_inv_scaled = time_inv_scaling(Contaminated, SACed, Clean, scaler_x)\n",
    "\n",
    "# 결과 Plot\n",
    "save_path = '../../../../result/data_10000/CNN/'\n",
    "save_title = 'CNN_IO_time_L_time-fftPSD'\n",
    "\n",
    "Result_Plot(Contaminated_inv_scaled, SACed_inv_scaled, Clean_inv_scaled, save_path, save_title) # inverse scaled data를 input으로 넣음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
