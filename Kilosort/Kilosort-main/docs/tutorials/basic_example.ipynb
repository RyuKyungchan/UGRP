{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example spike-sorting analysis with sample data\n",
    "\n",
    "This tutorial is also available as a [collab notebook](https://github.com/MouseLand/Kilosort/blob/main/docs/tutorials/kilosort4.ipynb)\n",
    "if you would like to try Kilosort4 without installing the code locally."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download example data\n",
    "\n",
    "This is an example electrophysiological recording from the International Brain Laboratory, recorded using a Neuropixels 1.0 probe (all data [here](https://ibl.flatironinstitute.org/public/)). The full recording is over 4000 seconds long, and the cropped recording is 90 seconds long.\n",
    "\n",
    "Downloading the recording may take a few minutes. If it fails, please try running the cell again.\n",
    "\n",
    "You can alternatively use any .bin file. See the \"Loading other data formats\" tutorial for loading other file extensions.\n",
    "When using your own data, be sure to check that you've specified the correct dtype (default is int16) and that the data is in row-major (or 'C') order, the default for NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZFM-02370_mini.imec0.ap.bin: 2.08GB [02:25, 14.3MB/s]                               \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NOTE: Be sure to update this filepath if you want the data downloaded to\n",
    "#       a specific location.\n",
    "# SAVE_PATH = Path('ZFM-02370_mini.imec0.ap.bin')\n",
    "SAVE_PATH = Path('C:/Users/stell/Desktop/SCH/UGRP/data/ZFM-02370_mini.imec0.ap.bin')\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    \"\"\" from https://stackoverflow.com/a/53877507 \"\"\"\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "## CROPPED DATASET\n",
    "URL = 'http://www.kilosort.org/downloads/ZFM-02370_mini.imec0.ap.bin'\n",
    "download_url(URL, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download channel maps for default probes\n",
    "from kilosort.utils import download_probes\n",
    "download_probes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run kilosort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort: Kilosort version 4.0.19\n",
      "kilosort.run_kilosort: Python version 3.10.15\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: System information:\n",
      "kilosort.run_kilosort: Windows-10-10.0.22631-SP0 AMD64\n",
      "kilosort.run_kilosort: Intel64 Family 6 Model 142 Stepping 12, GenuineIntel\n",
      "kilosort.run_kilosort: Using GPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort: Using CUDA device: NVIDIA GeForce GTX 1650 with Max-Q Design 4.00GB\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: Sorting C:\\Users\\stell\\Desktop\\SCH\\UGRP\\data\\ZFM-02370_mini.imec0.ap.bin\n",
      "kilosort.run_kilosort: Interpreting binary file as default dtype='int16'. If data was saved in a different format, specify `data_dtype`.\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: N samples: 2700000\n",
      "kilosort.run_kilosort: N seconds: 90.0\n",
      "kilosort.run_kilosort: N batches: 45\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  13.17s; total  13.19s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after preprocessing\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    12.70 %\n",
      "kilosort.run_kilosort: Memory:       95.87 %     |     15.15   /    15.80 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    `conda install pynvml` for GPU usage\n",
      "kilosort.run_kilosort: GPU memory:   77.45 %     |      3.10   /     4.00 GB\n",
      "kilosort.run_kilosort: Allocated:     0.21 %     |      0.01   /     4.00 GB\n",
      "kilosort.run_kilosort: Max alloc:    32.60 %     |      1.30   /     4.00 GB\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Number of universal templates: 1532\n",
      "kilosort.spikedetect: Detecting spikes...\n",
      "  0%|          | 0/45 [00:07<?, ?it/s]\n",
      "kilosort.spikedetect: Error in spikedetect.run on batch 0\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py\", line 263, in run\n",
      "    xy, imax, amp, adist = template_match(X, ops, iC, iC2, weigh, device=device)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py\", line 165, in template_match\n",
      "    Amax = torch.max(Aa[iC2], 0)[0]\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 880.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.27 GiB is allocated by PyTorch, and 906.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "kilosort.run_kilosort: Encountered error in `run_kilosort`:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py\", line 263, in run\n",
      "    xy, imax, amp, adist = template_match(X, ops, iC, iC2, weigh, device=device)\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py\", line 165, in template_match\n",
      "    Amax = torch.max(Aa[iC2], 0)[0]\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 880.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.27 GiB is allocated by PyTorch, and 906.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\run_kilosort.py\", line 227, in run_kilosort\n",
      "    ops, bfile, st0 = compute_drift_correction(\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\run_kilosort.py\", line 564, in compute_drift_correction\n",
      "    ops, st = datashift.run(ops, bfile, device=device, progress_bar=progress_bar,\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\datashift.py\", line 198, in run\n",
      "    st, _, ops  = spikedetect.run(\n",
      "  File \"c:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py\", line 289, in run\n",
      "    logger.debug(f'xy shape: {xy.shape}')\n",
      "UnboundLocalError: local variable 'xy' referenced before assignment\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'xy' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py:263\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(ops, bfile, device, progress_bar, clear_cache)\u001b[0m\n\u001b[0;32m    262\u001b[0m X \u001b[38;5;241m=\u001b[39m bfile\u001b[38;5;241m.\u001b[39mpadded_batch_to_torch(ibatch, ops)\n\u001b[1;32m--> 263\u001b[0m xy, imax, amp, adist \u001b[38;5;241m=\u001b[39m \u001b[43mtemplate_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miC2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m yct \u001b[38;5;241m=\u001b[39m yweighted(yc, iC, adist, xy, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py:165\u001b[0m, in \u001b[0;36mtemplate_match\u001b[1;34m(X, ops, iC, iC2, weigh, device)\u001b[0m\n\u001b[0;32m    164\u001b[0m imaxs[:, nb\u001b[38;5;241m*\u001b[39mt:nb\u001b[38;5;241m*\u001b[39m(t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m imax\n\u001b[1;32m--> 165\u001b[0m Amax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\u001b[43mAa\u001b[49m\u001b[43m[\u001b[49m\u001b[43miC2\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m Amaxs[:, nb\u001b[38;5;241m*\u001b[39mt:nb\u001b[38;5;241m*\u001b[39m(t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m Amax\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 880.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.27 GiB is allocated by PyTorch, and 906.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# NOTE: 'n_chan_bin' is a required setting, and should reflect the total number\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#       of channels in the binary file. For information on other available\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#       settings, see `kilosort.run_kilosort.default_settings`.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m'\u001b[39m: SAVE_PATH\u001b[38;5;241m.\u001b[39mparent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_chan_bin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m385\u001b[39m}\n\u001b[0;32m      8\u001b[0m ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate, kept_spikes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mrun_kilosort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneuropixPhase3B1_kilosortChanMap.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# save_preprocessed_copy=True\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\run_kilosort.py:227\u001b[0m, in \u001b[0;36mrun_kilosort\u001b[1;34m(settings, probe, probe_name, filename, data_dir, file_object, results_dir, data_dtype, do_CAR, invert_sign, device, progress_bar, save_extra_vars, clear_cache, save_preprocessed_copy, bad_channels, verbose_console)\u001b[0m\n\u001b[0;32m    225\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    226\u001b[0m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 227\u001b[0m ops, bfile, st0 \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_drift_correction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtic0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtic0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclear_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Check scale of data for log file\u001b[39;00m\n\u001b[0;32m    233\u001b[0m b1 \u001b[38;5;241m=\u001b[39m bfile\u001b[38;5;241m.\u001b[39mpadded_batch_to_torch(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\run_kilosort.py:564\u001b[0m, in \u001b[0;36mcompute_drift_correction\u001b[1;34m(ops, device, tic0, progress_bar, file_object, clear_cache)\u001b[0m\n\u001b[0;32m    554\u001b[0m whiten_mat \u001b[38;5;241m=\u001b[39m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhiten_mat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    556\u001b[0m bfile \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBinaryFiltered(\n\u001b[0;32m    557\u001b[0m     ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m], n_chan_bin, fs, NT, nt, twav_min, chan_map, \n\u001b[0;32m    558\u001b[0m     hp_filter\u001b[38;5;241m=\u001b[39mhp_filter, whiten_mat\u001b[38;5;241m=\u001b[39mwhiten_mat, device\u001b[38;5;241m=\u001b[39mdevice, do_CAR\u001b[38;5;241m=\u001b[39mdo_CAR,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m     file_object\u001b[38;5;241m=\u001b[39mfile_object\n\u001b[0;32m    562\u001b[0m     )\n\u001b[1;32m--> 564\u001b[0m ops, st \u001b[38;5;241m=\u001b[39m \u001b[43mdatashift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mclear_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m bfile\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    567\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrift computed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mtic\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms; \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m    568\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mtic0\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\datashift.py:198\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(ops, bfile, device, progress_bar, clear_cache)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ops, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# the first step is to extract all spikes using the universal templates\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m st, _, ops  \u001b[38;5;241m=\u001b[39m \u001b[43mspikedetect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_cache\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# spikes are binned by amplitude and y-position to construct a \"fingerprint\" for each batch\u001b[39;00m\n\u001b[0;32m    204\u001b[0m F, ysamp \u001b[38;5;241m=\u001b[39m bin_spikes(ops, st)\n",
      "File \u001b[1;32mc:\\Users\\stell\\anaconda3\\envs\\kilosort\\lib\\site-packages\\kilosort\\spikedetect.py:289\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(ops, bfile, device, progress_bar, clear_cache)\u001b[0m\n\u001b[0;32m    287\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError in spikedetect.run on batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mibatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    288\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 289\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mxy\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    292\u001b[0m log_performance(logger, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mibatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'xy' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from kilosort import run_kilosort\n",
    "\n",
    "# NOTE: 'n_chan_bin' is a required setting, and should reflect the total number\n",
    "#       of channels in the binary file. For information on other available\n",
    "#       settings, see `kilosort.run_kilosort.default_settings`.\n",
    "settings = {'data_dir': SAVE_PATH.parent, 'n_chan_bin': 385}\n",
    "\n",
    "ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate, kept_spikes = \\\n",
    "    run_kilosort(\n",
    "        settings=settings, probe_name='neuropixPhase3B1_kilosortChanMap.mat',\n",
    "        # save_preprocessed_copy=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to save a pre-processed copy of the data (including whitening, high-pass filtering, and drift correction), you can set `save_preprocessed_copy = True` in the arguments for `run_kilosort`. Alternatively, `kilosort.io.save_prepocessing` can be used as a standalone utility to generate the same copy from saved sorting results, but this will not update options for Phy. By default, results are saved in the same directory as the binary data in the `kilosort4` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kilosort.io import save_preprocessing, load_ops\n",
    "\n",
    "# NOTE: This will only create the .dat file, it will *NOT* update options for Phy.\n",
    "#       If you want to use this with Phy, you will need to modify `params.py`\n",
    "#       in the results directory to point to this new file. Additionally,\n",
    "#       you must set `hp_filtered=True` and `dtype='int16'`.\n",
    "ops_path = SAVE_PATH.parent / 'kilosort4' / 'ops.npy'\n",
    "ops = load_ops(ops_path)\n",
    "save_preprocessing(SAVE_PATH.parent / 'temp_wh.dat', ops, bfile_path=SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results\n",
    "\n",
    "Note: at this point, you can also load the results in `phy`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from kilosort.io import load_ops\n",
    "\n",
    "\n",
    "# outputs saved to results_dir\n",
    "results_dir = Path(settings['data_dir']).joinpath('kilosort4')\n",
    "ops = load_ops(results_dir / 'ops.npy')\n",
    "camps = pd.read_csv(results_dir / 'cluster_Amplitude.tsv', sep='\\t')['Amplitude'].values\n",
    "contam_pct = pd.read_csv(results_dir / 'cluster_ContamPct.tsv', sep='\\t')['ContamPct'].values\n",
    "chan_map =  np.load(results_dir / 'channel_map.npy')\n",
    "templates =  np.load(results_dir / 'templates.npy')\n",
    "chan_best = (templates**2).sum(axis=1).argmax(axis=-1)\n",
    "chan_best = chan_map[chan_best]\n",
    "amplitudes = np.load(results_dir / 'amplitudes.npy')\n",
    "st = np.load(results_dir / 'spike_times.npy')\n",
    "clu = np.load(results_dir / 'spike_clusters.npy')\n",
    "firing_rates = np.unique(clu, return_counts=True)[1] * 30000 / st.max()\n",
    "dshift = ops['dshift']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec, rcParams\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "gray = .5 * np.ones(3)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10), dpi=100)\n",
    "grid = gridspec.GridSpec(3, 3, figure=fig, hspace=0.5, wspace=0.5)\n",
    "\n",
    "ax = fig.add_subplot(grid[0,0])\n",
    "ax.plot(np.arange(0, ops['Nbatches'])*2, dshift);\n",
    "ax.set_xlabel('time (sec.)')\n",
    "ax.set_ylabel('drift (um)')\n",
    "\n",
    "ax = fig.add_subplot(grid[0,1:])\n",
    "t0 = 0 \n",
    "t1 = np.nonzero(st > ops['fs']*5)[0][0]\n",
    "ax.scatter(st[t0:t1]/30000., chan_best[clu[t0:t1]], s=0.5, color='k', alpha=0.25)\n",
    "ax.set_xlim([0, 5])\n",
    "ax.set_ylim([chan_map.max(), 0])\n",
    "ax.set_xlabel('time (sec.)')\n",
    "ax.set_ylabel('channel')\n",
    "ax.set_title('spikes from units')\n",
    "\n",
    "ax = fig.add_subplot(grid[1,0])\n",
    "nb=ax.hist(firing_rates, 20, color=gray)\n",
    "ax.set_xlabel('firing rate (Hz)')\n",
    "ax.set_ylabel('# of units')\n",
    "\n",
    "ax = fig.add_subplot(grid[1,1])\n",
    "nb=ax.hist(camps, 20, color=gray)\n",
    "ax.set_xlabel('amplitude')\n",
    "ax.set_ylabel('# of units')\n",
    "\n",
    "ax = fig.add_subplot(grid[1,2])\n",
    "nb=ax.hist(np.minimum(100, contam_pct), np.arange(0,105,5), color=gray)\n",
    "ax.plot([10, 10], [0, nb[0].max()], 'k--')\n",
    "ax.set_xlabel('% contamination')\n",
    "ax.set_ylabel('# of units')\n",
    "ax.set_title('< 10% = good units')\n",
    "\n",
    "for k in range(2):\n",
    "    ax = fig.add_subplot(grid[2,k])\n",
    "    is_ref = contam_pct<10.\n",
    "    ax.scatter(firing_rates[~is_ref], camps[~is_ref], s=3, color='r', label='mua', alpha=0.25)\n",
    "    ax.scatter(firing_rates[is_ref], camps[is_ref], s=3, color='b', label='good', alpha=0.25)\n",
    "    ax.set_ylabel('amplitude (a.u.)')\n",
    "    ax.set_xlabel('firing rate (Hz)')\n",
    "    ax.legend()\n",
    "    if k==1:\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title('loglog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = ops['probe']\n",
    "# x and y position of probe sites\n",
    "xc, yc = probe['xc'], probe['yc']\n",
    "nc = 16 # number of channels to show\n",
    "good_units = np.nonzero(contam_pct <= 0.1)[0]\n",
    "mua_units = np.nonzero(contam_pct > 0.1)[0]\n",
    "\n",
    "\n",
    "gstr = ['good', 'mua']\n",
    "for j in range(2):\n",
    "    print(f'~~~~~~~~~~~~~~ {gstr[j]} units ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('title = number of spikes from each unit')\n",
    "    units = good_units if j==0 else mua_units \n",
    "    fig = plt.figure(figsize=(12,3), dpi=150)\n",
    "    grid = gridspec.GridSpec(2,20, figure=fig, hspace=0.25, wspace=0.5)\n",
    "\n",
    "    for k in range(40):\n",
    "        wi = units[np.random.randint(len(units))]\n",
    "        wv = templates[wi].copy()  \n",
    "        cb = chan_best[wi]\n",
    "        nsp = (clu==wi).sum()\n",
    "        \n",
    "        ax = fig.add_subplot(grid[k//20, k%20])\n",
    "        n_chan = wv.shape[-1]\n",
    "        ic0 = max(0, cb-nc//2)\n",
    "        ic1 = min(n_chan, cb+nc//2)\n",
    "        wv = wv[:, ic0:ic1]\n",
    "        x0, y0 = xc[ic0:ic1], yc[ic0:ic1]\n",
    "\n",
    "        amp = 4\n",
    "        for ii, (xi,yi) in enumerate(zip(x0,y0)):\n",
    "            t = np.arange(-wv.shape[0]//2,wv.shape[0]//2,1,'float32')\n",
    "            t /= wv.shape[0] / 20\n",
    "            ax.plot(xi + t, yi + wv[:,ii]*amp, lw=0.5, color='k')\n",
    "\n",
    "        ax.set_title(f'{nsp}', fontsize='small')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kilosort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
